<!DOCTYPE html>
<html lang="zh-cn" >
<head>
  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  
  <meta name="author"
        content="guojing.io"/>

  
  <meta name="description" content="有个朋友说起表白的段子时编了一句: you are the etcd to my k8s cluster 。
"/>
  

  
  
  <meta name="keywords" content="Kubernetes, Devops, Python, Debian"/>
  

  
  <link rel="canonical" href="https://guojing.io/posts/etcd-ops/"/>

  

  <title>etcd 集群运维 &middot; 郭靖 I/O</title>

  <link rel="shortcut icon" href="https://guojing.io/images/favicon.ico"/>
  <link rel="stylesheet" href="https://guojing.io/css/animate.min.css"/>
  <link rel="stylesheet" href="https://guojing.io/css/remixicon.css"/>
  <link rel="stylesheet" href="https://guojing.io/css/zozo.css"/>
  <link rel="stylesheet" href="https://guojing.io/css/highlight.css"/>

  
  
</head>

<body>
<div class="main animated">
  <div class="nav_container animated fadeInDown">
  <div class="site_nav" id="site_nav">
    <ul>
      
      <li>
        <a href="/">首页</a>
      </li>
      
      <li>
        <a href="/posts/">归档</a>
      </li>
      
      <li>
        <a href="/tags/">标签</a>
      </li>
      
      <li>
        <a href="/days/">日常</a>
      </li>
      
      <li>
        <a href="/about/">关于</a>
      </li>
      
    </ul>
  </div>
  <div class="menu_icon">
    <a id="menu_icon"><i class="remixicon-links-line"></i></a>
  </div>
</div>

  <div class="header animated fadeInDown">
  <div class="site_title_container">
    <div class="site_title">
      <h1>
        <a href="https://guojing.io/">
          <span>郭靖 I/O</span>
          <img src="https://guojing.io/images/logo.png"/>
        </a>
      </h1>
    </div>
    <div class="description">
      <p class="sub_title">文科生 / 网管 / 看书写字 / 动漫 / 不爱国</p>
      <div class="my_socials">
        
        
        <a href="https://github.com/jing2uo" title="github" target="_blank"><i class="remixicon-github-fill"></i></a>
        
        
        
        <a href="mailto:mail@guojing.io" title="mail" target="_blank"><i class="remixicon-mail-fill"></i></a>
        
        
        <a href="https://guojing.io/index.xml" type="application/rss+xml" title="rss" target="_blank"><i class="remixicon-rss-fill"></i></a>
      </div>
    </div>
  </div>
</div>
<style>
      table{
        border-left:1px solid #000000;border-top:1px solid #000000;
        width: 100%;
        word-wrap:break-word; word-break:break-all;
      }
      table th{
      text-align:center;
      }
      table th,td{
        border-right:1px solid #000000;border-bottom:1px solid #000000;
      }
</style>

  <div class="content">
    <div class="post_page">
      <div class="post animated fadeInDown">
        <div class="post_title post_detail_title">
          <h2><a href='/posts/etcd-ops/'>etcd 集群运维</a></h2>
          <span class="date">2019.01.28</span>
        </div>
        <div class="post_content markdown"><p>有个朋友说起表白的段子时编了一句: <code>you are the etcd to my k8s cluster</code> 。</p>

<h2 id="集群的备份和恢复">集群的备份和恢复</h2>

<h3 id="添加备份">添加备份</h3>

<pre><code>#!/bin/bash
IP=123.123.123.123
BACKUP_DIR=/alauda/etcd_bak/
mkdir -p $BACKUP_DIR
export ETCDCTL_API=3
etcdctl --endpoints=http://$IP:2379 snapshot save $BACKUP/snap-$(date +%Y%m%d%H%M).db

# 备份一个节点的数据就可以恢复，实践中，为了防止定时任务配置的节点异常没有生成备份，建议多加几个
</code></pre>

<h3 id="恢复集群">恢复集群</h3>

<pre><code>#!/bin/bash

# 使用 etcdctl snapshot restore 生成各个节点的数据

# 比较关键的变量是
# --data-dir 需要是实际 etcd 运行时的数据目录
# --name  --initial-advertise-peer-urls  需要用各个节点的配置
# --initial-cluster  initial-cluster-token 需要和原集群一致

ETCD_1=10.1.0.5
ETCD_2=10.1.0.6
ETCD_3=10.1.0.7

for i in ETCD_1 ETCD_2 ETCD_3
do
export ETCDCTL_API=3
etcdctl snapshot restore snapshot.db \
--data-dir=/var/lib/etcd \
--name $i \
--initial-cluster ${ETCD_1}=http://${ETCD_1}:2380,${ETCD_2}=http://${ETCD_2}:2380,${ETCD_3}=http://${ETCD_3}:2380 \
--initial-cluster-token k8s_etcd_token \
--initial-advertise-peer-urls http://$i:2380 &amp;&amp; \
mv /var/lib/etcd/ etcd_$i
done
# 把 etcd_10.1.0.5 复制到 10.1.0.5节点，覆盖/var/lib/etcd(同--data-dir路径)
# 其他节点依次类推
</code></pre>

<h3 id="用etcd自动创建的snapdb恢复">用etcd自动创建的snapdb恢复</h3>

<pre><code>#!/bin/bash 
export ETCDCTL_API=3
etcdctl snapshot restore snapshot.db \
--skip-hash-check \
--data-dir=/var/lib/etcd \
--name 10.1.0.5 \
--initial-cluster 10.1.0.5=http://10.1.0.5:2380,10.1.0.6=http://10.1.0.6:2380,10.1.0.7=http://10.1.0.7:2380 \
--initial-cluster-token k8s_etcd_token \
--initial-advertise-peer-urls http://10.1.0.5:2380

# 也是所有节点都需要生成自己的数据目录，参考上一条
# 和上一条命令唯一的差别是多了  --skip-hash-check  （跳过完整性校验）
# 这种方式不能确保 100% 可恢复，建议还是自己加备份
# 通常恢复后需要做一下数据压缩和碎片整理，可参考相应章节
</code></pre>

<h3 id="踩过的坑">踩过的坑</h3>

<p>[ 3.0.14版 etcd restore 功能不可用 ] <a href="https://github.com/etcd-io/etcd/issues/7533">https://github.com/etcd-io/etcd/issues/7533</a></p>

<p>使用更新的 etcd 即可。</p>

<h2 id="集群的扩容">集群的扩容</h2>

<h3 id="从1到3">从1到3</h3>

<ol>
<li><p>执行添加</p>

<pre><code>#!/bin/bash
export ETCDCTL_API=2
etcdctl --endpoints=http://10.1.0.6:2379 member add 10.1.0.6 http://10.1.0.6:2380
etcdctl --endpoints=http://10.1.0.7:2379 member add 10.1.0.7 http://10.1.0.7:2380
   
# ETCD_NAME=&quot;etcd_10.1.0.6&quot; 
# ETCD_INITIAL_CLUSTER=&quot;10.1.0.6=http://10.1.0.6:2380,10.1.0.5=http://10.1.0.5:2380&quot;
# ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot;
</code></pre></li>

<li><p>准备添加的节点 etcd 参数配置</p>

<pre><code>#!/bin/bash
/usr/local/bin/etcd 
--data-dir=/data.etcd 
--name 10.1.0.6
--initial-advertise-peer-urls http://10.1.0.6:2380 
--listen-peer-urls http://10.1.0.6:2380 
--advertise-client-urls http://10.1.0.6:2379 
--listen-client-urls http://10.1.0.6:2379 
--initial-cluster 10.1.0.6=http://10.1.0.6:2380,10.1.0.5=http://10.1.0.5:2380
--initial-cluster-state exsiting
--initial-cluster-token k8s_etcd_token
   
# --initial-cluster 集群所有节点的 name=ip:peer_url
# --initial-cluster-state exsiting 告诉 etcd 自己归属一个已存在的集群，不要自立门户
</code></pre></li>

<li><p>踩过的坑</p></li>
</ol>

<p>从 1 到 3 期间，会经过集群是两节点的状态，这时候可能集群的表现就像挂了，endpoint status 这些命令都不能用，所以我们需要用member add先把集群扩到三节点，然后再依次启动etcd实例，这样做就能确保 etcd 就是健康的。</p>

<ol>
<li>从3到更多，其实还是member add啦，就放心搞吧。</li>
</ol>

<h2 id="集群加证书">集群加证书</h2>

<h3 id="生成证书">生成证书</h3>

<pre><code>curl -s -L -o /usr/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
curl -s -L -o /usr/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
chmod +x /usr/bin/{cfssl,cfssljson}
cd /etc/kubernetes/pki/etcd
</code></pre>

<pre><code>#  cat ca-config.json
{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;100000h&quot;
    },
    &quot;profiles&quot;: {
      &quot;server&quot;: {
        &quot;usages&quot;: [&quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot;],
        &quot;expiry&quot;: &quot;100000h&quot;
      },
      &quot;client&quot;: {
        &quot;usages&quot;: [&quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot;],
        &quot;expiry&quot;: &quot;100000h&quot;
      }
    }
  }
}
</code></pre>

<pre><code>#  cat ca-csr.json
{
  &quot;CN&quot;: &quot;etcd&quot;,
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 4096
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;L&quot;: &quot;Beijing&quot;,
      &quot;O&quot;: &quot;Alauda&quot;,
      &quot;OU&quot;: &quot;PaaS&quot;,
      &quot;ST&quot;: &quot;Beijing&quot;
    }
  ]
}
</code></pre>

<pre><code>#  cat server-csr.json
{
  &quot;CN&quot;: &quot;etcd-server&quot;,
  &quot;hosts&quot;: [
    &quot;localhost&quot;,
    &quot;0.0.0.0&quot;,
    &quot;127.0.0.1&quot;,
    &quot;所有master 节点ip &quot;,
    &quot;所有master 节点ip &quot;,
    &quot;所有master 节点ip &quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 4096
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;L&quot;: &quot;Beijing&quot;,
      &quot;O&quot;: &quot;Alauda&quot;,
      &quot;OU&quot;: &quot;PaaS&quot;,
      &quot;ST&quot;: &quot;Beijing&quot;
    }
  ]
}
</code></pre>

<pre><code># cat client-csr.json
{
  &quot;CN&quot;: &quot;etcd-client&quot;,
  &quot;hosts&quot;: [
    &quot;&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 4096
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;L&quot;: &quot;Beijing&quot;,
      &quot;O&quot;: &quot;Alauda&quot;,
      &quot;OU&quot;: &quot;PaaS&quot;,
      &quot;ST&quot;: &quot;Beijing&quot;
    }
  ]
}
</code></pre>

<pre><code>cd /etc/kubernetes/pki/etcd
cfssl gencert -initca ca-csr.json | cfssljson -bare ca
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server-csr.json | cfssljson -bare server
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client-csr.json | cfssljson -bare client
</code></pre>

<p>参考链接：<a href="https://lihaoquan.me/2017/3/29/etcd-https-setup.html">https://lihaoquan.me/2017/3/29/etcd-https-setup.html</a></p>

<h3 id="首先更新节点的peer-urls">首先更新节点的peer-urls</h3>

<pre><code class="language-shell">export ETCDCTL_API=3
etcdctl --endpoints=http://x.x.x.x:2379 member list
   #  1111111111  ..........
   #  2222222222  ..........
   #  3333333333  ..........
etcdctl --endpoints=http://172.30.0.123:2379 member update 1111111111 --peer-urls=https://x.x.x.x:2380
   # 执行三次把三个节点的peer-urls都改成https
</code></pre>

<h3 id="修改配置">修改配置</h3>

<pre><code>#  vim /etc/kubernetes/main*/etcd.yaml

#  etcd启动命令部分修改 http 为 https，启动状态改成 existing
    - --advertise-client-urls=https://x.x.x.x:2379
    - --initial-advertise-peer-urls=https://x.x.x.x:2380
    - --initial-cluster=xxx=https://x.x.x.x:2380,xxx=https://x.x.x.x:2380,xxx=https://x.x.x.x:2380
    - --listen-client-urls=https://x.x.x.x:2379
    - --listen-peer-urls=https://x.x.x.x:2380
    - --initial-cluster-state=existing

#  etcd 启动命令部分插入
	- --cert-file=/etc/kubernetes/pki/etcd/server.pem
	- --key-file=/etc/kubernetes/pki/etcd/server-key.pem
	- --peer-cert-file=/etc/kubernetes/pki/etcd/server.pem
	- --peer-key-file=/etc/kubernetes/pki/etcd/server-key.pem
	- --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.pem
	- --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.pem
	- --peer-client-cert-auth=true
	- --client-cert-auth=true

#  检索hostPath在其后插入
  - hostPath:
      path: /etc/kubernetes/pki/etcd
      type: DirectoryOrCreate
    name: etcd-certs

#  检索mountPath在其后插入
    - mountPath: /etc/kubernetes/pki/etcd
      name: etcd-certs

</code></pre>

<pre><code>#  vim /etc/kubernetes/main*/kube-apiserver.yaml
#  apiserver 启动部分插入，修改 http 为https
	- --etcd-cafile=/etc/kubernetes/pki/etcd/ca.pem
	- --etcd-certfile=/etc/kubernetes/pki/etcd/client.pem
	- --etcd-keyfile=/etc/kubernetes/pki/etcd/client-key.pem
	- --etcd-servers=https://x.x.x.x:2379,https://x.x.x.x:2379,https://x.x.x.x:2379
</code></pre>

<h3 id="遇到的坑">遇到的坑</h3>

<p>[ etcd加证书后，apiserver的健康检查还是http请求，etcd会一直刷日志 ]</p>

<p><a href="https://github.com/etcd-io/etcd/issues/9285">https://github.com/etcd-io/etcd/issues/9285</a></p>

<pre><code class="language-verilog">2018-02-06 12:41:06.905234 I | embed: rejected connection from &quot;127.0.0.1:35574&quot; (error &quot;EOF&quot;, ServerName &quot;&quot;)
</code></pre>

<p>解决办法：直接去掉apiserver的健康检查，或者把默认的检查命令换成curl (apiserver的镜像里应该没有curl，如果是刚需的话自己重新build一下吧 )</p>

<h2 id="集群升级">集群升级</h2>

<p>已经是 v3 的的集群不需要太多的配置，保留数据目录，替换镜像(或者二进制)即可；</p>

<p>v2到v3的升级需要一个merge的操作，我并没有实际的实践过，也不太推荐这样做。</p>

<h2 id="集群状态检查">集群状态检查</h2>

<p>其实上述所有步骤都需要这些命令的辅助——</p>

<pre><code>#!/bin/bash
# 如果证书的话，去掉--cert --key --cacert 即可
# --endpoints= 需要写了几个节点的url，endpoint status就输出几条信息

export ETCDCTL_API=3

etcdctl \
--endpoints=https://x.x.x.x:2379 \ 
--cert=/etc/kubernetes/pki/etcd/client.pem \
--key=/etc/kubernetes/pki/etcd/client-key.pem \
--cacert=/etc/kubernetes/pki/etcd/ca.pem \
endpoint status -w table

etcdctl --endpoints=xxxx endpoint health

etcdctl --endpoints=xxxx member list

kubectl get cs
</code></pre>

<h2 id="数据操作-删除-压缩-碎片整理">数据操作（删除、压缩、碎片整理）</h2>

<h3 id="删除">删除</h3>

<pre><code>ETCDCTL_API=2 etcdctl rm --recursive            # v2 的 api 可以这样删除一个“目录”
ETCDCTL_API=3 etcdctl --endpoints=xxx del /xxxxx --prefix # v3 的版本

# 带证书的话，参考上一条添加 --cert --key --cacert 即可
</code></pre>

<p>遇到的坑：在一个客户环境里发现Kubernetes集群里的 “事件” 超级多，就是 kubectl describe xxx 看到的events部分信息，数据太大导致 etcd 跑的很累，我们就用这样的方式删掉没用的这些数据。</p>

<h3 id="碎片整理">碎片整理</h3>

<pre><code>ETCDCTL_API=3 etcdctl --endpoints=xx:xx,xx:xx,xx:xx defrag
ETCDCTL_API=3 etcdctl --endpoints=xx:xx,xx:xx,xx:xx endpoint status # 看数据量
</code></pre>

<h3 id="压缩">压缩</h3>

<pre><code>ETCDCTL_API=3 etcdctl --endpoints=xx:xx,xx:xx,xx:xx compact

# 这个在只有 K8s 用的 etcd 集群里作用不太大，可能具体场景我没遇到
# 可参考这个文档
# https://www.cnblogs.com/davygeek/p/8524477.html
# 不过跑一下不碍事

etcd --auto-compaction-retention=1

# 添加这个参数让 etcd 运行时自己去做压缩
</code></pre>

<h2 id="常见问题">常见问题</h2>

<ol>
<li>etcd 对时间很依赖，所以集群里的节点时间一定要同步！</li>
<li>磁盘空间不足，如果磁盘是被 etcd 自己吃完了，就需要考虑压缩和删数据啦</li>
<li>加证书后所有请求就都要带证书了，要不会提示 <code>context deadline exceeded</code></li>
<li>做各个操作时 etcd 启动参数里标明节点状态的要小心，否则需要重新做一遍前面的步骤很麻烦</li>
</ol>

<h2 id="日志收集">日志收集</h2>

<p>etcd 的日志暂时只支持 syslog 和 stdout 两种——  <a href="https://github.com/etcd-io/etcd/issues/7936">https://github.com/etcd-io/etcd/issues/7936</a></p>

<p>etcd 的日志在排查故障时很有用，如果我们用宿主机来部署 etcd，日志可以通过 systemd 检索到，但kubeadm 方式启动的 etcd 在容器重启后就会丢失所有历史。我们可以用以下的方案来做——</p>

<ol>
<li><p>shell 的重定向</p>

<pre><code>etcd --xxxx --xxxx   &gt;  /var/log/etcd.log 
# 配合 logratate 来做日志切割
# 将日志通过 volume 挂载到宿主机
</code></pre></li>

<li><p>supervisor</p></li>
</ol>

<p>supervisor 从容器刚开始流行时，就是保持服务持续运行很有效的工具</p>

<ol>
<li>sidecar 容器（后续我在github上补充一个例子，github.com/jing2uo）</li>
</ol>

<p>sidecar可以简单理解为一个pod里有多个容器（比如kubedns）他们彼此可以看到对方的进程，因此我们可以用传统的 strace 来捕捉 etcd进程的输出，然后在sidecar这个容器里和shell重定向一样操作。</p>

<pre><code>   strace  -e trace=write -s 200 -f -p 1
</code></pre>

<h2 id="kubeadm-1-13部署的集群">kubeadm 1.13部署的集群</h2>

<p>最近我们测试kubernetes 1.13集群时发现了一些有趣的改变，诈一看我们上面的命令就没法用了——</p>

<p><a href="https://kubernetes.io/docs/setup/independent/ha-topology/">https://kubernetes.io/docs/setup/independent/ha-topology/</a></p>

<p>区分了 <code>Stacked etcd topology</code> 和 <code>External etcd topology</code> ，官方的链接了这个图很形象——</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/d1411cded83856552f37911eb4522d9887ca4e83/b94b2/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg" alt="Stacked etcd topology" /></p>

<p>这种模式下的 etcd 集群，最明显的差别是容器内 etcd 的initial-cluster 启动参数只有自己的 ip，会有点懵挂了我这该怎么去恢复。其实基本原理没有变，kubeadm 藏了个 configmap，启动参数被放在了这里 ——</p>

<pre><code>kubectl get cm  etcdcfg -n kube-system -o yaml
</code></pre>

<pre><code>    etcd:
      local:
        serverCertSANs:
        - &quot;192.168.8.21&quot;
        peerCertSANs:
        - &quot;192.168.8.21&quot;
        extraArgs:
          initial-cluster: 192.168.8.21=https://192.168.8.21:2380,192.168.8.22=https://192.168.8.22:2380,192.168.8.20=https://192.168.8.20:2380
          initial-cluster-state: new
          name: 192.168.8.21
          listen-peer-urls: https://192.168.8.21:2380
          listen-client-urls: https://192.168.8.21:2379
          advertise-client-urls: https://192.168.8.21:2379
          initial-advertise-peer-urls: https://192.168.8.21:2380
</code></pre>

<h2 id="联系我">联系我</h2>

<p>实践过程中 google 了大量文档和教程，整理时我尽量找了印象深刻的文档的历史补充进来，但时间过去了很久不可能搜集完整，如果发现某部分内容侵犯了版权，可以联系我删除内容或者补充参考链接。若文档表述或者知识点有问题，来 <a href="https://github.com/jing2uo/Blog">https://github.com/jing2uo/Blog</a> 提 issue 。</p></div>
        <div class="post_footer">
          
          <div class="meta">
            <div class="info">
              <span class="field tags">
                <i class="remixicon-stack-line"></i>
                
                <a href="https://guojing.io/tags/etcd/">etcd</a>
                
                <a href="https://guojing.io/tags/kubernetes/">kubernetes</a>
                
              </span>
            </div>
          </div>
          
        </div>
      </div>
      
      
    </div>
  </div>
  <a id="back_to_top" href="#" class="back_to_top"><span>△</span></a>
</div>
<footer class="footer">
  <div class="footer_slogan">
    <span>The quieter you become, the more you can hear.</span>
  </div>
</footer>



<script src="https://guojing.io/js/jquery-3.3.1.min.js"></script>
<script src="https://guojing.io/js/zozo.js"></script>
<script src="https://guojing.io/js/highlight.pack.js"></script>
<link  href="https://guojing.io/css/fancybox.min.css" rel="stylesheet">
<script src="https://guojing.io/js/fancybox.min.js"></script>

<script>hljs.initHighlightingOnLoad()</script>


  <script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-140400448-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




</body>
</html>
